{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patterns in Oregon Wildfires Milestone Report\n",
    "\n",
    "### John Wu jywu86@gmail.com\n",
    "\n",
    "Summary: \n",
    "\n",
    "Wildfires are a frequent occurrence all over Western United States cost millions and affect hundreds of thousands of lives each year.  The effects of such fires is hard to predict which creates an even bigger challenge for the firefighters that are trying to control it.  Factoring in weather patterns and historical fire data, we hope to find patterns and model predictions on the size and effects of these fires based on these factors.    \n",
    "\n",
    "In this Capstone project, we explore the fire patterns based on the Wildfire ODF dataset from the Oregon Department of Forestry.  The dataset involves over 12,000 documented cases of fires that occurred in the state of Oregon from 2005 to 2017.  We are able to see the size of the fires as well as the cause of the fire (man or nature).    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "Work with oregon fire data to predict the magnitude of wildfires in the Oregon area based on oregon fire data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "First I cleaned and analyzed the data by performing the following steps: \n",
    "\n",
    "1. Filter for blank values in the dataframe.  Some columns will not be used and are redundent, so I removed these columns.  \n",
    "2. Fill in blank values for ignition times to concatenate weather data from Dark Sky API.  I approximated the blank ignition times as reported times using the assumption that the time a fire is reported is not significantly far from the time the fire ignitied.\n",
    "3. Called for historical weather data using Dark Sky API on the latitude, longitude, and ignition time to create a dataframe with Humidity, Weather, Precipitation, Wind, Dewpoint, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "Next to prepare the data for processing, I looked at the different features and outliers that could potentially affect the predictions significantly. \n",
    "\n",
    "1. Outliers: looking for outliers that may affect the numbers, I ran a pairplot on all the features to graphically see where are potential outliers. From the first few graphs, it looked like most of the data resided in  between 0 and 100 total acres.  \n",
    "\n",
    "![title](img/pairplot1.png)\n",
    "\n",
    "2. Correlation and features: Running a correlation plot shows a slight correlation with temperature and a correlation with the number of days.  Surprisingly, wind does not seem to be a factor with the size of a fire.  \n",
    "![title](img/corr1.png)\n",
    "\n",
    "1. The pairplot was ran again by removing extreme values.  (Removing acres above 100 total acres)  From looking at these pairplots, it looks like the regression lines are much more similar.  \n",
    "![title](img/Pplot2.png)\n",
    "\n",
    "2. With the correlation plot for these smaller fires, it appears that temperature has less correlation than wind.  \n",
    "![title](img/corr2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intial Findings:\n",
    "### Time period (2005 to 2011 and 2011 to 2017)\n",
    "1. First looking at a signficance test of the total fire acres.  Based on the test, I reached a p-value of 0.057 which was not significant to the 95% interval but significant to 90%.  \n",
    "2. Looking at the temperature differences between the two time periods, I got a p-value of 0.324 which was not significant.  Based on these findings, it appears that the temperature may not be as big of a factor as another factor. \n",
    "\n",
    "### Area comparisons (EOA vs SOA vs NOA)\n",
    "\n",
    "1.Looking at differences of acres burned between the different areas. \n",
    "    a. Looking at the difference between EOA and NOA, there was signficance in the amount of acres burned.  (p-value of 3.1609e-08)\n",
    "    b. Looking at differences between SOA and NOA, there was no signficance with the same test.  (p-value of 0.637)\n",
    "    c. Looking at differences between EOA and SOA, there was signficance with the same test.  (p-value of 3.476e-19)\n",
    "\n",
    "2. Looking at the pairplot it appears that outliers affect the EOA area a lot more.  After removing the extreme values; all areas seem to be more well correlated.  Separating the dataset into larger fires and smaller fires would be my approach to modeling the dataset.  \n",
    "2. Based on the correlation of factors, it appears that Dew Point temperature and Humidity, may have a larger contributing factor to the size of fires.  Whether this is coincidence or an actual factor should be explored.  \n",
    "3. Another factor should be separating the data into seasons and seeing if seasonality really plays a large part in the size and amount of fires. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "When approaching the modeling portion of this project, I chose to use random forest as my model fit.  The reason for this is because my sample data from the initial EDA did not appear to have a normal distribution.  When graphing the QQ-plot, it is clear that the sample is not from a normally distributed.  Decision trees appear to be a good candidate for such model.  \n",
    "\n",
    "![title](img/QQplot.png)\n",
    "\n",
    "First, I ran the model for the full dataset.  I removed the ODFProtectedAcres feature in this dataset as this feature describes how much fires have burned into Oregon Forestry Protected Acres.  In a real life scenario, we would not be able to gather this feature until after the fire has already burned.  After running 100 decision trees, my R^2 for this model was 0.018529.  When moving this to 1000 decision trees, the R^2 value improves to 0.02128.  \n",
    "\n",
    "Next, I ran the model by filtering out the extreme values of high acreage fires since almost 98% of all fires are less than 100 acres.  By separating these datapoints from the dataset, I am hoping that the model will be able to generalize better.  Running a 100 decision tree random forest regressor, my R^2 value improved to 0.029109.  Running a 1000 decision tree random forest regressor, my R^2 value improved to 0.047092.  Comparing the feature importance selected from the random forest regressor.  \n",
    "\n",
    "Another model to consider for non normally distributed data is SVM.  In this case, I ran a SVR for the under100 dataset.  Seeing that the under100 generalizes better, I stuck to this dataset for modeling.  Testing for kernels: rbf, linear, and poly; I got MAEs of 2.76 with rbf, 1802 with linear, and 1030680 with poly.  From this, it is clear that the data trained on the rbf kernel performed much better on the test data and is compariable to the random forest regressor which gave a MAE of 2.56.\n",
    "\n",
    "Looking into the random forest regressor given that it yielded the best MAE, it appears that the longitude, duration of the fire, and temperature were the most important features.  When looking at the filtered dataset of fires that were under 100 acres, it appears as though there is less discernable differences in the features.  \n",
    "\n",
    "![title](img/FullDataImportance.png)\n",
    "\n",
    "![title](img/SmallImportance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "Given the result of the models used; I was unable to create an accurate predicitive model using this dataset.  Five out of the top ten most important features in finding these predictions was supplemented from DarkSky API and these features would help create a better predictive model than the dataset by itself.  However, given the result of the models; there could be other hidden features in the dataset that may lead to a more accurate result.  \n",
    "\n",
    "The next crucial steps for finding a good predicitive model on this dataset could be to speak with an expert about which other features could be important to include in predicting this.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links to code\n",
    "\n",
    "Code for data exploration: https://github.com/jywu86/Springboard/blob/master/CapStone1%20/Exploratory%20Data%20Analysis.ipynb\n",
    "\n",
    "Code for inferential statistics: \n",
    "https://github.com/jywu86/Springboard/blob/master/CapStone1%20/Inferential%20Statistics%20Capstone%201.ipynb\n",
    "\n",
    "Code for Data Wrangling: \n",
    "https://github.com/jywu86/Springboard/blob/master/Data%20Wrangling%20for%20Capstone%201.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
